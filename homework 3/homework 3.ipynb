{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "## Xin Ou (xo2119)  Xiaoyu Shi (xs2375)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting for notebook and show the Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a pipeline \n",
    "\n",
    "This class creates a simple pipeline that writes all found items to a JSON file, where each line contains one JSON element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('Legoresultt.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spider\n",
    "\n",
    "The LegosSpider class defines from which URLs to start crawling and which values to retrieve. I set the logging level of the crawler to warning, otherwise the notebook is overloaded with DEBUG messages about the retrieved data. I will extract the information includes 'Name','Pieces','Tags','Year' of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class LegosSpider(scrapy.Spider):\n",
    "    name = \"lego\"\n",
    "    start_urls = ['https://brickset.com/sets/theme-Disney']\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'Legoresultt.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for LEGO in response.css('.set'):\n",
    "            yield {\n",
    "                'Name': LEGO.css('h1 ::text').extract_first(),\n",
    "                'Pieces': LEGO.xpath('.//dl[dt/text() = \"Pieces\"]/dd/a/text()').extract_first(),\n",
    "                'Tags': LEGO.css('div.tags span a::text').extract(),\n",
    "                'Year': LEGO.css('div.tags a.year::text').extract()             \n",
    "            }\n",
    "            \n",
    "        NEXT_PAGE_SELECTOR = '.next a ::attr(href)'\n",
    "        next_page = response.css(NEXT_PAGE_SELECTOR).extract_first()\n",
    "        if next_page:\n",
    "            yield scrapy.Request(\n",
    "                response.urljoin(next_page),\n",
    "                callback=self.parse\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 13:52:18 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: scrapybot)\n",
      "2020-02-17 13:52:18 [scrapy.utils.log] INFO: Versions: lxml 4.4.1.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (default, Aug 13 2019, 15:17:50) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.7, Platform Darwin-19.0.0-x86_64-i386-64bit\n",
      "2020-02-17 13:52:18 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'Legoresultt.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x111867610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(LegosSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the files\n",
    "\n",
    "Verify that the files has been created on disk. As we can observe the files are both created and have data. The .jl file has line separated JSON elements, while the .json file has one big JSON array containing all the legos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 kelanox  staff  14681 Feb 17 13:52 Legoresultt.jl\r\n",
      "-rw-r--r--@ 1 kelanox  staff  14754 Feb 17 13:52 Legoresultt.json\r\n"
     ]
    }
   ],
   "source": [
    "ll Legoresultt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Name\": \"Cogsworth\", \"Pieces\": null, \"Tags\": [\"Disney\", \" France\", \" In Store Build\", \" Toys R Us\", \" Brick Built Figure\", \" Beauty And The Beast\"], \"Year\": [\"2016\", \"2016\"]}\r\n",
      "{\"Name\": \"Lumiere\", \"Pieces\": null, \"Tags\": [\"Disney\", \" France\", \" Lumiere\", \" In Store Build\", \" Toys R Us\", \" Brick Built Figure\", \" Beauty And The Beast\"], \"Year\": [\"2016\", \"2016\"]}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 Legoresultt.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Name\": \"Cogsworth\", \"Pieces\": null, \"Tags\": [\"Disney\", \" France\", \" In Store Build\", \" Toys R Us\", \" Brick Built Figure\", \" Beauty And The Beast\"], \"Year\": [\"2016\", \"2016\"]}\r\n",
      "{\"Name\": \"Lumiere\", \"Pieces\": null, \"Tags\": [\"Disney\", \" France\", \" Lumiere\", \" In Store Build\", \" Toys R Us\", \" Brick Built Figure\", \" Beauty And The Beast\"], \"Year\": [\"2016\", \"2016\"]}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 Legoresultt.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes\n",
    "Pandas can now be used to create dataframes and save the frames to pickles. The .json file can be loaded directly into a frame, whereas for the .jl file we need to specify the JSON objects are divided per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pieces</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Rapunzel's Market Visit</td>\n",
       "      <td>37.0</td>\n",
       "      <td>[Rapunzel,  Polybag,  Disney,  Cart,  Baked Go...</td>\n",
       "      <td>[2014, 2014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Olaf's Summertime Fun</td>\n",
       "      <td>48.0</td>\n",
       "      <td>[Olaf,  Polybag,  Disney,  Musical,  Beach,  S...</td>\n",
       "      <td>[2016, 2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Cinderella's Kitchen</td>\n",
       "      <td>37.0</td>\n",
       "      <td>[Cinderella,  Polybag,  Disney,  Kitchen,  Cin...</td>\n",
       "      <td>[2017, 2017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ariel's Underwater Symphony</td>\n",
       "      <td>51.0</td>\n",
       "      <td>[Ariel,  Polybag,  Disney,  Musical,  Piano,  ...</td>\n",
       "      <td>[2018, 2018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Elsa's Winter Throne</td>\n",
       "      <td>42.0</td>\n",
       "      <td>[Elsa,  Polybag,  Disney,  Ice,  Frozen,  Roya...</td>\n",
       "      <td>[2019, 2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Aurora]</td>\n",
       "      <td>[2020, 2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>Arendelle Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Microscale,  Castle,  Disney]</td>\n",
       "      <td>[2019, 2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>Olaf Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2019, 2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>Cogsworth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Disney,  France,  In Store Build,  Toys R Us,...</td>\n",
       "      <td>[2016, 2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>Lumiere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Disney,  France,  Lumiere,  In Store Build,  ...</td>\n",
       "      <td>[2016, 2016]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name  Pieces  \\\n",
       "0       Rapunzel's Market Visit    37.0   \n",
       "1         Olaf's Summertime Fun    48.0   \n",
       "2          Cinderella's Kitchen    37.0   \n",
       "3   Ariel's Underwater Symphony    51.0   \n",
       "4          Elsa's Winter Throne    42.0   \n",
       "..                          ...     ...   \n",
       "66                       Aurora     NaN   \n",
       "67             Arendelle Castle     NaN   \n",
       "68                     Olaf Box     NaN   \n",
       "69                    Cogsworth     NaN   \n",
       "70                      Lumiere     NaN   \n",
       "\n",
       "                                                 Tags          Year  \n",
       "0   [Rapunzel,  Polybag,  Disney,  Cart,  Baked Go...  [2014, 2014]  \n",
       "1   [Olaf,  Polybag,  Disney,  Musical,  Beach,  S...  [2016, 2016]  \n",
       "2   [Cinderella,  Polybag,  Disney,  Kitchen,  Cin...  [2017, 2017]  \n",
       "3   [Ariel,  Polybag,  Disney,  Musical,  Piano,  ...  [2018, 2018]  \n",
       "4   [Elsa,  Polybag,  Disney,  Ice,  Frozen,  Roya...  [2019, 2019]  \n",
       "..                                                ...           ...  \n",
       "66                                           [Aurora]  [2020, 2020]  \n",
       "67                     [Microscale,  Castle,  Disney]  [2019, 2019]  \n",
       "68                                                 []  [2019, 2019]  \n",
       "69  [Disney,  France,  In Store Build,  Toys R Us,...  [2016, 2016]  \n",
       "70  [Disney,  France,  Lumiere,  In Store Build,  ...  [2016, 2016]  \n",
       "\n",
       "[71 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfjson = pd.read_json('Legoresultt.json')\n",
    "dfjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explains which database you would use to store this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I will use the relational database to store this data. From the final dataframe, we can make some conclusions:\n",
    "- A relational database is one that presents information in tables with rows and columns. \n",
    "- A table is a collection of objects of the same type(rows). \n",
    "- The ability to retrieve these related data provides us the term relational database.\n",
    "\n",
    "I choose PostgreSQL (often referred to as Postgres) which is an object-relational database management system (ORDBMS) with an emphasis on extensibility and standards-compliance. PostgreSQL also has a number of JSON functions and operators that can be used with its two JSON data types (JSON, and JSONB).\n",
    "\n",
    "PostgreSQL is also a relational database that is much more concerned with standards compliance and extensibility than with giving you freedom over how you store data. It uses both dynamic and static schemas and allows you to use it for relational data and normalized form storage. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
